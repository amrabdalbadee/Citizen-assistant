# ğŸ›ï¸ Citizen Support Assistant

An AI-powered voice-first service assistant for government services. This prototype demonstrates how citizens can interact with government information through both text and voice, receiving accurate, context-aware guidance.

## âœ¨ 100% FREE - No API Keys Required!

This project runs entirely on your local machine using:
- **Ollama** - Local LLM (Llama 3.2)
- **Faster-Whisper** - Local speech-to-text
- **Edge TTS** - Free Microsoft neural voices
- **ChromaDB** - Local vector database
- **Sentence Transformers** - Local embeddings

## ğŸ¯ Features

- **Multi-Modal Input**: Accept both text and audio (voice) queries
- **Speech-to-Text**: Automatic transcription using Whisper (optimized with faster-whisper)
- **Intelligent Retrieval**: RAG-based answers strictly from official knowledge documents
- **Text-to-Speech**: Neural voice synthesis for audio responses (accessibility)
- **Session Management**: Context-aware follow-up questions within a session
- **Hallucination Prevention**: Strict grounding in source documents with confidence scoring

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CITIZEN SUPPORT ASSISTANT                          â”‚
â”‚                            (100% Local & Free)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Client  â”‚â”€â”€â”€â”€â–¶â”‚                   FastAPI Server                      â”‚  â”‚
â”‚  â”‚(Web/App) â”‚     â”‚                                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚                   â”‚  â”‚ /query      â”‚  â”‚ /query/audioâ”‚  â”‚ /session    â”‚   â”‚  â”‚
â”‚                   â”‚  â”‚ (Text)      â”‚  â”‚ (Voice)     â”‚  â”‚ (History)   â”‚   â”‚  â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                â”‚                              â”‚
â”‚                             â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                             â”‚         â”‚ STT Service â”‚  â—„â”€â”€ FREE (Local)     â”‚
â”‚                             â”‚         â”‚ (Whisper)   â”‚                       â”‚
â”‚                             â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                             â”‚                â”‚                              â”‚
â”‚                             â–¼                â–¼                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                   â”‚          RAG Pipeline               â”‚                   â”‚
â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚                   â”‚  â”‚  Embeddings â”‚  â”‚   ChromaDB  â”‚  â”‚  â—„â”€â”€ FREE (Local) â”‚
â”‚                   â”‚  â”‚(MiniLM-L6)  â”‚â—€â–¶â”‚(Vector Store)â”‚  â”‚                   â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚                   â”‚         â”‚                          â”‚                   â”‚
â”‚                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚                   â”‚  â”‚  Retriever  â”‚â”€â”€â–¶â”‚   Ollama    â”‚  â”‚  â—„â”€â”€ FREE (Local) â”‚
â”‚                   â”‚  â”‚   (k=4)     â”‚  â”‚ (Llama 3.2) â”‚  â”‚                   â”‚
â”‚                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                                       â”‚ TTS Service â”‚  â—„â”€â”€ FREE (Edge TTS)  â”‚
â”‚                                       â”‚ (Edge TTS)  â”‚                       â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start (M1 Mac)

### Prerequisites

- **Ollama** installed and running (see Step 1)
- **Python 3.11+** or **Docker**

### Step 1: Install Ollama

```bash
# Install Ollama (if not already installed)
# Download from: https://ollama.ai/download

# Pull the Llama 3.2 model (recommended for M1)
ollama pull llama3.2

# Verify Ollama is running
ollama list
```

### Step 2: Clone and Configure

```bash
# Clone the repository
cd citizen-assistant

# Copy environment template (no API keys needed!)
cp .env.example .env
```

### Step 3: Run the Application

#### Option A: Streamlit UI (Recommended) ğŸ¨

The Streamlit frontend provides a beautiful chat interface with:
- ğŸ’¬ Conversation history stored in SQLite database
- ğŸ¤ Voice input (upload audio files)
- ğŸ”Š Text-to-speech responses
- ğŸ¤– LLM model selector
- ğŸ“š Source citations

```bash
# Make script executable
chmod +x run_streamlit.sh

# Run the Streamlit app
./run_streamlit.sh

# Or manually:
source venv/bin/activate
pip install -r requirements.txt
cd streamlit_app
streamlit run app.py
```

**Open:** http://localhost:8501

#### Option B: FastAPI Backend (For API access)

```bash
# Run the backend API
./run.sh

# Or manually:
source venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**Open:** http://localhost:8000/docs

#### Option C: Run with Docker

```bash
# Streamlit UI only (recommended)
docker compose up streamlit --build

# Or both UI and API
docker compose --profile api up --build
```

### Step 4: Test the Application

**Streamlit UI:** Open http://localhost:8501 and start chatting!

**API (if running):**
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "How do I apply for a passport?"}'
```

---

## ğŸ–¥ï¸ Streamlit UI Features

### Chat Interface
- Clean, modern chat UI with message bubbles
- Real-time streaming responses
- Confidence indicators for each response
- Expandable source citations

### Conversation Management
- ğŸ“ Persistent storage in SQLite database
- ğŸ” Search through past conversations
- ğŸ“ Auto-generated conversation titles
- ğŸ—‘ï¸ Delete conversations

### Multimodal Support
- ğŸ“ Text input
- ğŸ¤ Audio file upload (WAV, MP3, OGG, M4A)
- ğŸ”Š Text-to-speech responses (multiple voices)

### Model Selection
- Switch between Ollama models on-the-fly
- Shows installed vs. available models
- Recommended models for M1 Mac:
  - `llama3.2` - Fast, good quality
  - `mistral` - Excellent quality
  - `llama3.1:8b` - Best quality

## ğŸ“ Project Structure

```
citizen-assistant/
â”œâ”€â”€ app/                        # FastAPI Backend
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py          # API endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag_service.py     # RAG pipeline (LangChain + ChromaDB)
â”‚   â”‚   â”œâ”€â”€ stt_service.py     # Speech-to-Text (Whisper)
â”‚   â”‚   â”œâ”€â”€ tts_service.py     # Text-to-Speech (Edge TTS)
â”‚   â”‚   â””â”€â”€ session_service.py # Session management
â”‚   â””â”€â”€ main.py                # FastAPI application
â”‚
â”œâ”€â”€ streamlit_app/              # Streamlit Frontend
â”‚   â”œâ”€â”€ app.py                 # Main Streamlit application
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ models.py          # SQLite database for conversations
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ chat_service.py    # Chat service with RAG
â”‚   â””â”€â”€ components/            # Reusable UI components
â”‚
â”œâ”€â”€ knowledge/                  # Knowledge base documents
â”‚   â”œâ”€â”€ passport_application.txt
â”‚   â””â”€â”€ birth_certificate.txt
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ docs/                       # Documentation
â”‚
â”œâ”€â”€ Dockerfile                  # Backend container
â”œâ”€â”€ Dockerfile.streamlit        # Frontend container
â”œâ”€â”€ docker-compose.yml          # Docker orchestration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run.sh                      # Run backend script
â”œâ”€â”€ run_streamlit.sh            # Run frontend script
â”œâ”€â”€ Makefile                    # Convenience commands
â”œâ”€â”€ .env.example               # Environment template
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_PROVIDER` | `groq` | LLM provider: `groq`, `openai`, or `ollama` |
| `LLM_MODEL` | `llama-3.3-70b-versatile` | Model identifier |
| `GROQ_API_KEY` | - | Groq API key (required if using Groq) |
| `STT_MODEL` | `base` | Whisper model size: `tiny`, `base`, `small`, `medium`, `large-v3` |
| `STT_DEVICE` | `cpu` | Compute device: `cpu` or `cuda` |
| `TTS_ENABLED` | `true` | Enable text-to-speech responses |
| `CHUNK_SIZE` | `500` | Document chunk size for embedding |
| `RETRIEVAL_K` | `4` | Number of chunks to retrieve |

### Adding Knowledge Documents

Place `.txt` files in the `knowledge/` directory. The system will automatically ingest them on startup.

Or use the API:

```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{"filename": "new_service.txt", "content": "Document content here..."}'
```

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/query` | Process text query |
| POST | `/api/v1/query/audio` | Process audio query |
| GET | `/api/v1/session/{id}` | Get session information |
| DELETE | `/api/v1/session/{id}` | Delete session |
| POST | `/api/v1/ingest` | Ingest new knowledge document |
| GET | `/api/v1/health` | Health check |
| GET | `/api/v1/stats` | System statistics |

Full API documentation available at `/docs` (Swagger UI) or `/redoc`.

## ğŸ¯ Design Decisions

### Why Ollama (Default LLM)?

- **Cost**: 100% FREE - runs locally on your machine
- **Privacy**: Data never leaves your computer
- **M1 Optimized**: Excellent performance on Apple Silicon
- **Easy Setup**: Just `ollama pull llama3.2`
- **Offline**: Works without internet connection
- **Alternative**: Can easily switch to Groq (free cloud) or OpenAI

### Recommended Models for M1 Mac

| Model | Size | Speed | Quality | Use Case |
|-------|------|-------|---------|----------|
| `llama3.2` | 2B | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜†â˜† | Fast responses, simple Q&A |
| `llama3.2:3b` | 3B | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† | Better quality, still fast |
| `mistral` | 7B | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | Excellent quality |
| `llama3.1:8b` | 8B | â˜…â˜…â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | Best quality, slower |

### Why Faster-Whisper (STT)?

- **Performance**: 4x faster than original Whisper via CTranslate2
- **Memory**: INT8 quantization reduces memory by ~50%
- **Accuracy**: Comparable to original Whisper models
- **Free**: No API costs, runs completely locally
- **M1 Compatible**: Works great on Apple Silicon

### Why ChromaDB (Vector Store)?

- **Simplicity**: Embedded database, no external setup
- **Performance**: Fast similarity search with HNSW
- **Persistence**: Data survives restarts
- **Free**: Open source, no costs
- **Migration Path**: Easy to swap for Pinecone/Weaviate in production

### Why Edge TTS?

- **Quality**: Microsoft's neural TTS voices
- **Cost**: 100% FREE, no API key required
- **Variety**: Multiple languages and voices
- **Async**: Non-blocking synthesis

## âš¡ Latency Optimization

1. **STT Optimization**:
   - `beam_size=1` for faster decoding
   - VAD filter to skip silence
   - INT8 quantization

2. **LLM Optimization**:
   - Groq's LPU for sub-second inference
   - Limited conversation history
   - Streaming support (configurable)

3. **Retrieval Optimization**:
   - Pre-computed embeddings
   - HNSW index for approximate NN search
   - Optimal chunk size (500 chars)

4. **Architecture**:
   - Async throughout (FastAPI + async services)
   - Singleton pattern for model reuse
   - Connection pooling

## ğŸ“ˆ Scalability Considerations

For handling 1,000+ concurrent requests:

### Current Architecture (Prototype)
- Single instance, in-memory sessions
- Embedded ChromaDB
- Suitable for ~50-100 concurrent users

### Production Scaling Strategy

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Load Balancer  â”‚
                    â”‚    (nginx)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ API #1  â”‚        â”‚ API #2  â”‚        â”‚ API #3  â”‚
    â”‚(FastAPI)â”‚        â”‚(FastAPI)â”‚        â”‚(FastAPI)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚  Redis  â”‚   â”‚Pinecone â”‚   â”‚  LLM    â”‚
         â”‚(Sessions)â”‚  â”‚(Vectors)â”‚   â”‚ (Groq)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Changes for Scale:**
1. **Sessions**: Replace in-memory with Redis Cluster
2. **Vector Store**: Migrate to Pinecone or Weaviate (managed)
3. **API**: Deploy multiple instances behind load balancer
4. **STT**: Use cloud APIs (Deepgram, AssemblyAI) for parallel processing
5. **Caching**: Add response caching for common queries

## ğŸ”’ Security & Accuracy

### Hallucination Prevention
- System prompt explicitly restricts answers to source documents
- Confidence scoring based on retrieval relevance
- "I don't have information" fallback for low-confidence queries

### Data Privacy (Government Context)
- No data sent to external services except LLM inference
- Session data automatically expires
- Audio files cleaned up after processing
- No PII logging

### Input Validation
- Pydantic models for all inputs
- File type validation for audio
- Query length limits

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

### Manual Testing

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Text query with session
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "What documents do I need for a new passport?"}'

# Follow-up question (use session_id from previous response)
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "How much does it cost?", "session_id": "<SESSION_ID>"}'

# Get session history
curl http://localhost:8000/api/v1/session/<SESSION_ID>
```

## ğŸ› ï¸ Development

### Local Development (without Docker)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export GROQ_API_KEY=your_key_here

# Run the application
uvicorn app.main:app --reload --port 8000
```

### Code Quality

```bash
# Format code
black app/ tests/
isort app/ tests/

# Type checking
mypy app/

# Linting
ruff check app/
```

## ğŸ“‹ Handling Edge Cases

### Ambiguous Queries
The system handles vague queries by:
1. Retrieving most relevant documents
2. Providing available information with lower confidence
3. Suggesting clarification when needed

### Unrelated Queries
For questions outside the knowledge base:
- Returns: "I don't have information about that in my knowledge base"
- Suggests contacting the relevant government office
- Does NOT hallucinate or make up information

### Poor Audio Quality
- Confidence score reflects transcription quality
- Returns error message if transcription fails
- Suggests re-recording with clearer speech

## ğŸ“ License

MIT License - See LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

---

**Built for Government Service Excellence** ğŸ›ï¸
